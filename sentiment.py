# -*- coding: utf-8 -*-
"""SENTIMENT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ROS1s791NAnR1ZF1hX72fHzK5zxz0-Y1
"""

!pip install datasets transformers==4.28.0
!pip install transformers[torch]
!pip install accelerate -U
!pip install torchinfo
!pip install tensorflow==2.14.0
!pip install sentencepiece
!pip install langdetect

!pip install torchinfo

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import langdetect
#from torchinfo import summary
import transformers
from transformers import AutoTokenizer
from transformers import TrainingArguments
from transformers import AutoModelForSeq2SeqLM
from transformers import AutoModelForSequenceClassification
from transformers import Trainer
from transformers import pipeline
from datasets import load_metric
from datasets import list_metrics
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import textwrap
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time
from enum import Enum
from nltk.tokenize import sent_tokenize
import json
import warnings
warnings.filterwarnings("ignore")

class Mode(Enum):
    FastInference = 1
    HighQualityInference = 2
    Custom = 3

nltk.download('punkt')
nltk.download('stopwords')

"""-------ABOVE DEPENDENCIES---------"""

#tokenizer = AutoTokenizer.from_pretrained("/content/drive/MyDrive/SIH_Model2")
#model = AutoModelForSequenceClassification.from_pretrained("/content/drive/MyDrive/SIH_Model2")

text = "This is a not great product. I hate it!"
inputs = tokenizer(text, return_tensors="pt")

outputs = model(**inputs)
logits = outputs.logits
predicted_class = torch.argmax(logits, dim=1)
confidence=logits[predicted_class]

predicted_class

logits

import torch.nn.functional as F

probabilities = F.softmax(logits, dim=1)

# Get the confidence score for the predicted class
confidence_score = torch.max(probabilities).item()

# Print the confidence score
print(f"Confidence Score: {confidence_score:.2f}")

import warnings
warnings.filterwarnings("ignore")

raw_datasets = load_dataset("mteb/tweet_sentiment_extraction")

raw_datasets

# checkpoint = "bert-base-uncased"
checkpoint = "cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

def tokenize_fn(batch):
  return tokenizer(batch['text'], truncation=True)

tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)

training_args = TrainingArguments(
  'my_trainer',
  evaluation_strategy='epoch',
  save_strategy='epoch',
  num_train_epochs=1,
)

model = AutoModelForSequenceClassification.from_pretrained(
    checkpoint,
    num_labels=3)

model

# summary(model, input_size=(16,512), dtypes=['torch.IntTensor'], device='cpu')
summary(model)

params_before = []
for name, p in model.named_parameters():
  params_before.append(p.detach().cpu().numpy())

metrics_list = list_metrics()
print(metrics_list)

metric = load_metric("accuracy")

metric.compute(predictions=[1, 0, 1], references=[1, 0, 0])

def compute_metrics(logits_and_labels):
  logits, labels = logits_and_labels
  predictions = np.argmax(logits, axis=-1)
  return metric.compute(predictions=predictions, references=labels)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

trainer.train()

trainer.save_model('/content/drive/MyDrive/SIH_Model2')

pip install keras

newmodel = pipeline('text-classification', model='/content/drive/MyDrive/SIH_Model2', device=0)

model = AutoModelForSequenceClassification.from_pretrained(
    "/content/drive/MyDrive/SIH_Model2",
    num_labels=3)

tp = pipeline("text-classification", model="/content/drive/MyDrive/SIH_Model2")

newmodel('This policy is discriminative')

newmodel('The policy is against certain parts of society')

# Load the tokenizer and model
model_checkpoint = "Helsinki-NLP/opus-mt-bn-en"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="pt")
model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)

# Encode the input text
input_text = "আপনি কি করছেন"
inputs = tokenizer(input_text, return_tensors="pt")

# Generate the translated text
outputs = model.generate(**inputs)

# Decode the translated text
translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

# Print the translated text
print(translated_text)

text = "আপনি কি করছেন"
language = langdetect.detect(text)

print(language)

"""------MODEL------------"""

import pandas as pd
import numpy as np
import textwrap
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time
from enum import Enum

class Mode(Enum):
    FastInference = 1
    HighQualityInference = 2
    Custom = 3

import pandas as pd
import numpy as np
import textwrap
import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time

nltk.download('punkt')
nltk.download('stopwords')

class TextExtraction:
    def __init__(self):
        self.mode="Extractive"
        self.featurizer = TfidfVectorizer(stop_words=stopwords.words('english'), norm='l2')
        self.result=""

    @staticmethod
    def wrap(x):
        return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)

    def summarise(self, text, reduction=0.10):
        start=time.time()
        self.result=""
        sents = nltk.sent_tokenize(text)
        #for i in sents:
            #print(i)
        n=len(sents)
        #print("Sentences: ", n)
        X = self.featurizer.fit_transform(sents)
        S = cosine_similarity(X)
        S /= S.sum(axis=1, keepdims=True)
        U = np.ones_like(S) / len(S)
        factor = 0.15
        S = (1 - factor) * S + factor * U
        eigenvals, eigenvecs = np.linalg.eig(S.T) #Transpose
        limiting_distribution=eigenvecs[:,0] / eigenvecs[:,0].sum()
        scores=limiting_distribution
        sort_idx = np.argsort(-scores)
        count=1+int(n*reduction)
        print("Total: ",n)
        print("Selecting: ",count)
        #print("Generated summary:")
        '''
        for i in sort_idx[:count]:
            print(wrap("%.2f: %s" % (scores[i], sents[i])))
        '''
        for i in sort_idx[:count]:
            self.result+=sents[i]
        for i in sort_idx[:-int(0.5*count)]:
            self.result+=sents[i]
        end=time.time()
        return {"mode":self.mode, "result":self.result, "delay": end-start}

from transformers import T5ForConditionalGeneration, T5Tokenizer

class AbstractiveTextSummariser:
    def __init__(self):
        self.mode="Abstractive"
        self.model = T5ForConditionalGeneration.from_pretrained("t5-small")
        self.tokenizer = T5Tokenizer.from_pretrained("t5-small")
        self.result=""

    def summarise(self, text, reduction=0.33):
        # Tokenize and summarize the text
        start=time.time()
        inputs = self.tokenizer.encode("summarize: " + text, return_tensors="pt", max_length=1024, truncation=True)
        summary_ids = self.model.generate(inputs, max_length=300, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)

        # Decode the summary
        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)
        self.result=summary
        end=time.time()
        return {"mode":self.mode, "result":self.result, "delay": end-start}



text="Greetings, friends!\nI have made multiple videos on the Indian education system,\ncomparing Indian education system with that of German system and the system in  Singapore\nand elaborating on the demerits of the Indian system\nBut my main criticism regarding the Indian education system in all these videos was\nWhy is our system so poor? What changes can be brought about\nand what can we learn from the developed countries?\nI have kept reiterating these main points in all these videos\nToday, I am very happy to say that the new education policy that our government has brought in\nThey have addressed almost all the major points of criticism in their new policy\nand they have brought a revolutionary change in the Indian education system\nI'm saying that in a positive step- They've taken a very good step\nCome, let us find out\nOne of the first and major points of criticism is that\nour educational system tries to fit the students into three categories after class 10\nScience, commerce and humanities\nAnd this is very problematic- If you chose one stream, then you cannot study the subjects of the other streams\nBut more often than not, the students are interested in a variety of subjects\nFor example, when I was in the 11th, I chose the science stream but\nmy interest also lay in Political science and Economics\nBut I was helpless, having opted for the science stream, I could not study subjects like Pol Science and Economics\nWhat could I have done?\nBut now, the government has changed this\nNow, the students have more flexibility to choose their subjects\nUpon the implementation of this policy,\na student can study Political science with Physics and Chemistry with History\nA student can study Science, commerce as well as Arts subjects\nThis is an amazing initiative. And I feel jealous as a 90s kid\nwe were compelled to choose amongst the three\nNow, the students would have so much more flexibility to choose\nA second major change by the government is that they have replaced the existing 10+2 academic structure\nwith the 5+3+3+4 system now\nNow, it has become more similar to the education system of the western developed countries\nIn the 10+2 system, education began at the age of 6\nIn this new system, education would now start at the age of 3\nPreschool would be from the age of 3-6 and then class 1 and 2 for the next two years\nThen would be the \"preparatory stage\" for the next 3 years in which focus would be upon\nplaying, discovery and activity based classroom learning\nClass 6 to 8 would be the middle stage\nin which experiential learning would be focused upon-\nsciences, mathematics, arts, social sciences and humanities\nNext would be the secondary stage of class 9-12\nin which multi disciplinary studies would be focused upon\nStudents would be provided with  ore flexibility and more choices\nThe job of selling, or working in a supermarket, or driving...\n-... plumbing, carpentry\ngardening... all the jobs like these\nthat do not come under the proper purview of engineering, humanities or universities\nAll that is viewed on the extra side,  they are vocationally trained upto a large extent\n- A vast difference is that in India, we view these jobs at a very low level\nWe look at things and presume that the people of the lower (caste/class) do these kinds of jobs\nand our parents poke fun and say that if you don't study, will you do carpentry and become a carpenter ?\nor a plumber?\nThe difference (here) is that these jobs are given the same respect in Germany\nI kept reiterating in the previous videos that vocational training is given a lot of importance in developed countries\nThe jobs like welding, electrician, carpentry, plumbing\nThese jobs are viewed at the same level as the rest of the skilled jobs\nIn India, these jobs are looked at with disdain, which is a mindset that needs to change\nThe government has implemented some structural changes to change this mindset, which is praiseworthy\nfor example, right from class 6, students would have to do internships in vocational training jobs\nThe students would be imparted experience in such jobs\nThere would be a bagless period of 10 days- where he students would take no bags to school\nbut experience jobs like- carpentry, welding, gardening\nVocational training in schools would be focused upon even later\nThis is a very critical thing without which, in my opinion, we cannot become a developed country\nuntil and unless these changes are implemented\nThe government has fortunately taken a step in the right direction regarding this\nCoding would be taught to children from class 6\nand the importance accorded to board exams in class 10 and 12 would be reduced\nAnother interesting and positive policy change is that the report cards handed to students at the year end\nthat is, the progress report,\nUntil now, the teachers assess how the student has performed in the entire year, according to them\nNow, assessment will be done by not only the teachers, but the students will also self evaluate themselves\nand say how have they performed in the entire year, according to their perspective\nNot only will there be self evaluation, the rest of the students of the class with also evaluate and say\nhow a particular student has performed according to the perspective of the rest of the classmates\nThis is a very useful step\nBecause critical thinking is a very important aspect- to evaluate oneself by oneself\nto think about what one is doing and critically analyze one's own decisions\nAnd in the coming life...\nWe are told how we are performing by our teachers and parents, when we are in school\nBut when the school and college life gets over, there is no one to tell you how your performance is going\nYou have to do a self evaluation of how you are performing in life\nand what you want to do ahead in life\nSo, this thinking should be imparted at an early stage to the students\nto evaluate oneself and to see what others think about you\nand what your evaluation is, from their perspective\nIt is very useful\nAnother important change-\nI have kept on saying in my videos that the government should spend more on education\nSeems as if the government has finally paid heed!\nThe government has decided that atleast 6% of the GDP will ow be spent on education\nRight now, it is around 3%- which is insufficient\nAnd compared to the developed countries and the rest of the developing countries,\nIndia spends very less on education in measure of the percentage of the GDP\n6% is a great target\nBut a lot depends on implementation as well- How soon is the government able to achieve it\nBut obviously, as a first step, setting a target of 6% is commendable\nThere was a problem of rote learning in the Indian education system\n. Most of the exams are designed in a way that we need to memorize things\nAnd all that we learnt, evaporates in a few months because we gave exams by rote learning\nSo, the government has also said that it would try and change this as well\nThe exams would be designed a way that would not require much memorization or rote learning\nBut how exactly this will be achieved is not clearly mentioned. So, it remains to be seen\nI'm hopeful that positive changes will be implemented here as well\nTalking about education after class 12- there is a multiple entry and exit programme\nIt means that- say, you started a degree- a B.tech degree\nand one year later, you realize that you do not want to continue with it because you don't like it\nSo, you can drop midway. All the subjects that you have studied for one year,\nyou can take their credits and get it transferred to another degree\nThis is extremely useful and already exists in most of the developed countries\nIt's great that this option will be available in India as well\nThis option now includes another feature- say the degree is of four years\nIf you drop out after one year, then you will get a certificate\nIf you drop out after the second year, then you will get a diploma\nAfter three years, you will get a bachelor's degree and after four years - a bachelor's research degree\nIf you have already done a four year degree in bachelors, MA and MSc degrees would only be of one year\nand two years if you have a bachelor's degree of three years\nThis is again consistent with the international standard\nTop 100 foreign institutes have been given permission to set up their campuses within India\nWhat's interesting is that this is a policy that Congress wanted to bring in when it was in power\nbut back then, BJP had opposed it. And now, it itself is bringing it in\nFocussing on vocational education, the government has said that in the next ten years,\nit will be integrated in all the schools and higher educational institutions in a phased manner\nIt is being aimed that by 2025, 50% of the learners in schools and higher educational institutions\nwill have had exposure to vocational education\nA common national professional standard will be set for all the teachers by 2022\nA four years integrated BA degree would be the minimum qualification required to become a teacher by 2030\nThese, in my opinion were the positive points brought by the government in this new policy\nLet us now talk about the negative/controversial points\nwhich are being criticized by the people\nThis new policy has been criticized the most on the point of language\nThis policy reads that, \"wherever possible the medium of instruction till 5th grade\nand preferably till class 8 and beyond will be the home language, local language or the  regional language\"\nThat is, the education of the child until the 5th grade should be in home language, mother language and regional language\nIt is nowhere written that doing so is compulsory\nBut those who criticize it say that this will force the schools to not teach in English\nand instead teach in regional languages\nwhich will not be beneficial for most of the people\nSay, you live in Kerala and your child has studied until class 4 in Kerala\nThereupon, you shift to Maharashtra\nMost of the schools would teach in Marathi in Maharashtra\nand the child will not be able to adjust\nThis would restrict the movement of the people from one state to another\nand this might have a detrimental effect\nIt is written in the policy that no language would be forced. Although, it is also said that\nthey would try to make Sanskrit and other classical languages available at every level in schools as an option\nand after class 9, the options of foreign languages will also be available like they are right now\nIn my opinion, it is important to give priority to English because today,\nEnglish, in a way , has become a global language of communication worldwide\nNo matter which country you come from, I believe it is essential to learn English\nif you want to do any thing at an international level\nIt is becoming essential to learn English in every country\nAnd this is an advantage for India in comparison to China and the rest of the South East Asian countries\nbecause there, people are not able to learn English to this extent\nSince people in India speak English, they are able to compete in western countries, US and Europe\nSecond- Several student and teachers' bodies have criticized this policy of being anti democratic\nSome parties have also criticized it. For example, CPI(M) has put forward the most criticism\nThey allege that the states were not consulted before making this policy\nSince education is a concurrent subject that comes under both the Centre as well as state list\nthe states should have been consulted more before introducing this policy\nIt is also alleged that this policy promotes centralization because this policy has a point that\nstates that a new teachers' training board will be set up for all kinds of teachers in the country\nand no state can change that\nThe power has been taken from the states and placed with the central government\nThe powers have been made more centralized that\nthe decision making regarding education would be done by the center\nAnd finally, some points of criticism said that this policy is very theoretical\nIt does change things theoretically. But to implement them practically in real life\nis going to be a very long drawn and difficult process\nbecause there are so many government schools where children in the 5th class have no teachers\nand sound infrastructure is not available in schools\nThe students are not educated properly and they drop out early\nThere are so many government schools with a serious dearth of available  teachers\nso how are they going to impart vocational training and give the option of variety of subjects to children\nAll this seems impossible to give\nThis is another point of criticism\nbecause all these changes being brought superficially are extremely difficult to implement in reality\nIn my opinion, it is a legit point of criticism\nand it is to be seen how much of these policies are implemented\nand what changes are seen on the ground level in reality\nI hope you would have liked this video. Share it if you found it to be informative\nIf you like my work, you can support me on Patreon.com/Dhruvrathee\nor by becoming a member on YouTube by clicking on the join button\nso that I may continue to make such videos for you in the future\nI'd like to thank Kuvera App for sponsoring this video\nKuvera is a mutual funds platform as well free advisory platform\non which you can invest in mutual funds as per your goals\nIt helps you decide what mutual fund should you invest in as per your goals?\nOn here, you can even invest in gold, that is, digital gold\nKuvera and Amazon have brought an amazing save and shop offer for you\nIf you're planning to shop in the future, then you can invest upto 90K rupees in the Kuvera App\nthen you can get a return of upto 6% per annum\nYou can redeem the money when you want to do shopping\nand if you buy Amazon vouchers with it,\nthen you will get a 3% Topup from Amazon\nYou will get the link to download the app in the description below\nand we will meet again in the next video\nThank you\n"

from nltk.tokenize import sent_tokenize

sentences = sent_tokenize(text)
chunk_size = 2
chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]

chunks

ET = TextExtraction()

ET.summarise(text)

AT= AbstractiveTextSummariser()

t=AT.summarise(text)

t['result']

langdetect.detect("Hi Hello what you doing")

class ClassificationPipeline:
    def __init__(self, mode=Mode.FastInference):
        self.mode=mode
        #if(self.mode==Mode.FastInference):
           #self.classifier=pipeline('text-classification', model='/content/drive/MyDrive/SIH_Model1', device=0)

        self.tokenizer = AutoTokenizer.from_pretrained("/content/drive/MyDrive/SIH_Model2")
        self.model = AutoModelForSequenceClassification.from_pretrained("/content/drive/MyDrive/SIH_Model2")
        self.AT=AbstractiveTextSummariser()
        self.ET=TextExtraction()
        self.summary=""
        self.sentiment_labels = ["Negative", "Neutral", "Positive"]

    def split(self, text, addContext=False):
        sentences = sent_tokenize(text)
        chunk_size = 1
        chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]
        if addContext:
            self.genSummary(text)
            if self.summary!="":
                for i in range(len(chunks)):
                    chunks[i].append(self.summary)
        return chunks

    def genSummary(self, text):
        self.summary=self.AT.summarise(text)['result']

    def translate(self, textInput):
        language = langdetect.detect(textInput)
        if language=="en":
            return textInput
        if language=="te":
            language="tl"
        model_checkpoint = "Helsinki-NLP/opus-mt-"+language+"-en"
        tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="pt")
        model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
        inputs = tokenizer(textInput, return_tensors="pt")
        outputs = model.generate(**inputs)
        translatedText = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return translatedText


    def sentiment(self, textInput):
        try:
            textInput=self.translate(textInput)
            #print(textInput)
            inputs = self.tokenizer(textInput, return_tensors="pt")
            outputs = self.model(**inputs)
            logits = outputs.logits
            predicted_class = torch.argmax(logits, dim=1)
            #print(f"Sentiment: {self.sentiment_labels[predicted_class]}")
            probabilities = F.softmax(logits, dim=1)
            # Get the confidence score for the predicted class
            confidence_score = torch.max(probabilities).item()
            # Print the confidence score
            #print(f"Confidence Score: {confidence_score:.2f}")
            return (predicted_class.item(), confidence_score)
        except Exception as e:
            #print("An exception occurred:", e)
            return (0,0)

    def evaluate(self, textInput, largeText=False, verbose=False):
        sentiment=0
        if largeText:
            chunks=self.split(textInput, addContext=False)
            mergedChunks=[]
            for chunk in chunks:
                temp=""
                for i in chunk:
                    temp=temp+i
                #mergedChunks.append(self.ET.summarise(temp)['result'])
                mergedChunks.append(temp)
            #print(mergedChunks)
            nonZeroResults=0 #To keep Count of Successful Results
            for chunk in mergedChunks:
                #print(len(chunk))
                #print("CHUNK: ", chunk)
                result=self.sentiment(chunk)
                if result==(0,0):
                    #print("FAILED")
                    continue

                if result[0]==1:
                    #IN CASE OF NEUTRAL AND LOW CONFIDENCE SCORE, IT CAN BE EITHER NEGATIVE OR POSITIVE
                    if result[1]<0.80: #So skip less confident ones
                        continue
                    sentiment+=1.0
                    nonZeroResults+=1
                    if verbose:
                        print("Weighted Sentiment = ", 1.0)

                elif result[0]==0:

                    sentiment+=result[0] + (1-result[1])  # 0 + (1-0.8) =0.2, else all negative ones will give 0
                    nonZeroResults+=1
                    if verbose:
                        print("Weighted Sentiment = ", result[0] + (1-result[1]))

                elif result[0]==2:

                    #sentiment+=result[0]*result[1]  # 2 * (0.9) = 1.8
                    sentiment+=1+result[1]
                    nonZeroResults+=1
                    if verbose:
                        print("Weighted Sentiment = ", 1+result[1])



                #if result!=(0,0):
                    #nonZeroResults+=1
            print("Successfully Analysed Chunks: ", nonZeroResults)
            if verbose:
                print("Sentiment Analysis: ", sentiment/nonZeroResults)
            finalSentiment=sentiment/nonZeroResults
            finalSentiment=finalSentiment-1
            #print("[-1 Negative]  [0 Neutral]  [1 Positive]")
            print("Sentiment: ", finalSentiment)
            #return mergedChunks
            return finalSentiment
        else:
            result=self.sentiment(textInput)

            print("Sentiment Label: ", result[0])
            print("Confidence: ", result[1])

        #textInput=self.translate(textInput)
        #result=self.classifier(textInput)
        #if result[0]['label']=='LABEL_0':
            #print("Sentiment: Negative")
        #elif result[0]['label']=='LABEL_1':
            #print("Sentiment: Neutral")
        #elif result[0]['label']=='LABEL_2':
            #print("Sentiment: Positive")
        #print("Confidence: ", result[0]['score'])

CP=ClassificationPipeline()

CP.evaluate("यह कानून आम आदमी के लिए हितकारी है.")

#India's new Policy on Education is certianly questionable and has met with criticism internationally
CP.evaluate("La nouvelle politique indienne en matière d'éducation est certainement discutable et a suscité des critiques au niveau international.")

with open('/content/result (1).json', 'r') as file:
    data = json.load(file)

def resultToSentiment(result):
    if result<-0.6:
        print("Sentiment: Strongly Negative")
    elif result>-0.6 and result<-0.25:
        print("Sentiment: Mildly Negative")
    elif result>-0.25 and result<0.25:
        print("Sentiment: Neutral")
    elif result>0.25 and result<0.6:
        print("Sentiment: Mildly Positive")
    elif result>0.6:
        print("Sentiment: Strongly Postive")

print("Sentiment Analysis\n")
print("[-1 Negative]  [0 Neutral]  [1 Positive]\n")
for i in data:
    print("State: ", i)
    result=CP.evaluate(data[i][0], largeText=True)
    resultToSentiment(result)
    print("\n")

